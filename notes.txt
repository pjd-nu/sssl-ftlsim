10/17/2012

4/25/2012
test.sh:
    for f in 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.3 2.6 2.9 4.2 4.5 5.0 5.5 6.0 6.5 7.0 8 9 10; do
	echo fffff $f
	python multi-pool.py $f
    done
(actually single LRU pool w/ 128 and 16-page blocks)
process:
awk '(/ffff/){nn=$2}/^[0-9]/{if (NF==3){print nn,$3}}' typescript  | dbcoldefine f A | dbmultistats --key=f A | dbcol f mean conf_low conf_high | dbsort -n f > data.dat

4/20/2012
moved cleaning selection into Python - 2.6s

4/18/2012
runlru - U = 23020, Np = 128, random, S_f = 0.2, running U*Np steps:
  simple python code - 275s [runlru.py]
  moved int_write() and host_write() into C - 32.4 s [runlru2.py]
  used C source for uniform, run() - 6.67 s [runlru3]
  using C source for writes, warmup - 2.37 s [runlru4]
  old greedy.c - 2s

4/17/2012 - python code is awfully slow.
Fin1 trace (4M lines, 5.6M writes):
 9.9s pypy
 28.1s python
to just iterate over all the addresses.

simple C parser for trace file:
 7.8s python (SWIG doesn't work with pypy)

random source, 5.6M addresses:
 29.9s python
 1.1s pypy
 28.2s - python w/ iterator
 5.5s - C SWIG version


